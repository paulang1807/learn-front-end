{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $$Statistics \\ Cheat \\ Sheet \\ - \\ RV$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1A. Discrete Random Variables\n",
    "**Probability Mass Function (pmf)**, $p(x)$ for a random variable $X$ is given by \n",
    "$$p(x) = p_X(x) = P(X = x) = P(\\{w \\in \\Omega:X(w) = x\\})$$ where $x$ is a value of the discrete RV $X$ and belongs to the set of real numbers $$\\{x \\in R :f(x) \\gt 0\\}$$ and maps to the outcomes w and $(X = x)$ is the corresponding event.<BR>\n",
    "Also,\n",
    "    $$p(x) \\geq 0$$ and\n",
    "    $$\\sum_xp(x) = 1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1B. Continuous Random Variables\n",
    "For any two numbers a and b, the **probability density function (pdf)** of a continuous RV $X$ is given by\n",
    "$$P(a \\leq X \\leq b) = \\int_a^bf(x)\\ dx$$ where \n",
    "$$f(x) \\geq 0$$ for all $x$ and \n",
    "$$\\int_{-\\infty}^{\\infty}f(x) \\ dx = 1$$ is the area under the entire graph of $f(x)$. \n",
    "\n",
    "$f(x)dx$ is the probability that $X$ is in an infinitesimal range around $x$ of width $dx$.\n",
    "\n",
    "Also, $$P(a \\leq X \\leq b) = P(a \\lt X \\lt b) = P(a \\lt X \\leq b) = P(a \\leq X \\lt b)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Continuous RV at any single value**\n",
    "$$P(X = c) = \\int_c^cf(x) \\ dx = \\lim_{\\epsilon \\to 0} \\int_{c - \\epsilon}^{c + \\epsilon} f(x) \\ dx = 0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Distribution of Probability Mass Function (PMF) \n",
    "The distribution of the pmf is the distribution of $X$ across all possible outcomes, i.e. $P(X=x_1), P(X=x_2),...,P(X=x_n)$ <BR>\n",
    "\n",
    "**Bernoulli Random Variable**<BR>\n",
    "For a Bernoulli RV, possible outcomes are $\\{0,1\\}$ and so the pmf distrbution will be the distribution for $P(X=0)$ and $P(X=1)$. If $P(X=1)=\\alpha$, then $P(X=0) = 1 - \\alpha$. Hence\n",
    "$$p(x; \\alpha) = \\begin{cases}\n",
    "1 - \\alpha, & \\ \\text{if x = 0} \\\\\n",
    "\\alpha, & \\ \\text{if x = 1} \\\\\n",
    "0, & \\ \\text{otherwise}\n",
    "\\end{cases}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Geometric Distributions**\n",
    "$$p(x) = \\begin{cases}\n",
    "(1 - p)^xp, & \\ x = 0,1,2,3,... \\\\\n",
    "0, & \\ \\text{otherwise}\n",
    "\\end{cases}$$\n",
    "$$= \\begin{cases}\n",
    "(1 - p)^{x-1}p, & \\ x = 1,2,3,... \\\\\n",
    "0, & \\ \\text{otherwise}\n",
    "\\end{cases}$$\n",
    "where $x$ is the number of failures before the first success"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Probability Density Function (PDF) \n",
    "**Continuous RV with uniform distribution**\n",
    "$$f(x; A,B) = \\begin{cases}\n",
    "\\frac{1}{B - A}, & \\ A \\leq x \\leq B \\\\\n",
    "0, & \\ otherwise\n",
    "\\end{cases}$$\n",
    "\n",
    "For n independent RVs,\n",
    "$$f(x_1,...,x_n; \\theta) = \\begin{cases}\n",
    "\\frac{1}{\\theta^n}, & \\ 0 \\leq x_1 \\leq \\theta,...,0 \\leq x_n \\leq \\theta \\\\\n",
    "0, & \\ otherwise\n",
    "\\end{cases}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Cumulative Density Function (CDF) \n",
    "**Discrete RV with pmf p(X)**\n",
    "$$F(x) = P(X \\leq x) = \\sum_{y:y \\leq x}p(y)$$\n",
    "$$F(x) = \\begin{cases}\n",
    "0, & \\ -\\infty \\lt x \\lt x_1 \\\\\n",
    "f(x_1), & \\ x_1 \\leq x \\lt x_2 \\\\\n",
    "f(x_1) + f(x_2), & \\ x_2 \\leq x \\lt x_3 \\\\\n",
    "\\vdots & \\ \\vdots \\\\\n",
    "f(x_1) + ...f(x_n), & \\ x_n \\leq x \\lt \\infty\n",
    "\\end{cases}$$\n",
    "\n",
    "**Bernoulli Random Variable**\n",
    "$$F(x; \\alpha) = \\begin{cases}\n",
    "0, & \\  x \\lt 0 \\\\\n",
    "1 - \\alpha, & \\  0 \\leq x \\lt 1 \\\\\n",
    "1, & \\ x \\geq 1\n",
    "\\end{cases}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Geometric Distributions**\n",
    "$$F(x) = P(X \\leq x) = \\begin{cases}\n",
    "0, & \\ x \\lt 1 \\\\\n",
    "1 - (1 - p)^{[x]}, & \\ x \\geq 1 \n",
    "\\end{cases}$$\n",
    "where $[x]$ is the largest integer $\\leq x$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Continuous RV**\n",
    "$$F(x) = P(X \\leq x) = \\int_{-\\infty}^x f(y) \\ dy $$\n",
    "$$F(x) = P(X \\gt x) = \\int_x^{\\infty} f(y) \\ dy $$\n",
    "$$P(X \\lt -x) = P(X \\gt x)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Continuous RV with uniform distribution**\n",
    "$$F(x) = \\int_{-\\infty}^xf(y) \\ dy = \\int_A^x \\frac{1}{B - A} dy = \\frac{x - A}{B - A}$$\n",
    "$$F(x) = \\begin{cases}\n",
    "0, & \\ x \\lt A \\\\\n",
    "\\frac{x - A}{B - A}, & \\ A \\leq x \\leq B \\\\\n",
    "1, & \\ x \\geq B\n",
    "\\end{cases}$$\n",
    "$\\implies$ For any $Z \\sim U[0,1]$ and $a \\in (0,1), P(Z \\lt a) = a$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Obtaining pmf from cdf \n",
    "For any two numbers a and b , $a \\leq b$,\n",
    "$$P(a \\leq X \\leq b) = F(b) - F(a-)$$ where \"a-\" is the largest possible X value that is strictly less than a.<BR>\n",
    "If only possible values are integers and if a and b are integers, then\n",
    "    $$P(a \\leq X \\leq b) = F(b) - F(a - 1)$$ and \n",
    "    $$P(X = a) = F(a) - F(a - 1)$$\n",
    "    $$P(X \\geq a) = 1 - F(a) = 1 - F(X \\leq a)$$\n",
    "    \n",
    "$$f(x) = F(x) - \\lim_{u \\to x^-}F(u)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Obtaining pdf from cdf \n",
    "$$P(X \\gt a) = 1 - F(a)$$\n",
    "$$P(a \\leq X \\leq b) = F(b) - F(a)$$\n",
    "\n",
    "**Fundamental Theorem Of Calculus**<BR>\n",
    "If $X$ is a continuous rv with pdf $f(x)$ and cdf $F(x)$, then at every $x$ at which the derivative $F'(x)$ exists\n",
    "$$ F'(x) = \\frac{d}{dx} F(x) = f(x)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Percentile of a continuous distribution\n",
    "The **(100p)th percentile** of the distribution of a continuous RV $\\eta(p)$ is \n",
    "$$p = F(\\eta(p)) = \\int_{-\\infty}^{\\eta(p)}f(y) \\ dy$$\n",
    "where p is a number between 0 and 1 <BR>\n",
    "Also, this is the same as the **pth quantile** of $X$ which is the value $q_p$ such that $P(X \\leq q_p) = p$\n",
    "    \n",
    "In R, use **qnorm** function to calculate quantiles\n",
    "\n",
    "**Deciles** are expressed as $10^{th}$. For example, $3^{rd}$ decile is equal to 3/10 or 0.3 quantile\n",
    "\n",
    "**Quartiles** are expressed as $4^{th}$. For example, $3^{rd}$ quartile is equal to 3/4 or 0.75 quantile or 75th percentile\n",
    "    \n",
    "The **median** of a continuous RV is the 50th percentile \n",
    "$$.5 = F(\\eta(.5)) = F(\\tilde\\mu)$$\n",
    "Equivalently, median can be calculated by solving for x in\n",
    "$$P(X \\leq x) = 0.5$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Expected or Mean value \n",
    "**Discrete RV**\n",
    "$$E(X) = \\mu_X = \\sum_{x \\in D}x . p(x)$$\n",
    "where X is a discrete RV with set of possible values D and pmf p(x) <BR>\n",
    "If $p(x_i)=p(x_j) \\ \\forall \\ i,j$, i.e. each outcome has the same probability and hence equal likelihood of happening, then\n",
    "    $$E(X) = p(x)\\sum_{i = 1}^kx_k = \\frac{1}{k} \\sum_{i = 1}^kx_k$$\n",
    "    where 1/k is the probability of k terms with equal likelihood <BR>\n",
    "$$\\mu_{h(X)} = E[h(X)] = \\sum_Dh(x).p(x)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DRV geometric series**\n",
    "$$E(X) = \\sum_D x. p(x) = \\sum_{x=1}^{\\infty}xp(1-p)^{x-1} = p\\sum_{x=1}^{\\infty}x(1-p)^{x-1} = p \\sum_{x=1}^{\\infty}\\biggl[ - \\frac{d}{dp}(1-p)^x \\biggl] = \\frac{1}{p}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DRV harmonic series**\n",
    "$$\\mu = E(X) = \\sum_{x=1}^{\\infty}x.\\frac{k}{x^2} = k\\sum_{x=1}^{\\infty}\\frac{1}{x} = \\infty$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Continuous RV**\n",
    "$$\\mu_X = E(X) = \\int_{-\\infty}^{\\infty}x.f(x) \\ dx$$\n",
    "$$\\mu_{h(X)} = E[h(X)] = \\int_{-\\infty}^{\\infty}h(x).f(x) \\ dx$$\n",
    "\n",
    "**Uniform Distribution**\n",
    "$$E(X) = \\frac{A + B}{2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. Rules of Expected Value\n",
    "For any linear function $h(X) = aX + b $,\n",
    "$$E(aX + b) = a. E(X) + b$$\n",
    "$$\\mu_{aX + b} = a. \\mu_X + b$$\n",
    "\n",
    "$$E(X + Y) = E(X) + E(Y)$$\n",
    "$$E(aX + bY) = aE(X) + bE(Y)$$\n",
    "\n",
    "If $X$ and $Y$ are independent,\n",
    "$$E(XY) = E(X)E(Y)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. Variance of X\n",
    "**Discrete RV**\n",
    "$$V(X) = \\sigma_X^2 = \\sum_D(x - \\mu)^2 . p(x) = E[(x- \\mu)^2]$$\n",
    "$$V(X) = \\sigma_X^2 = \\biggl[\\sum_D x^2 .p(x)\\biggl] - \\mu^2 = E(X^2) - [E(X)]^2 = E(X^2) - \\mu^2$$\n",
    "\n",
    "**Continuoius RV**\n",
    "$$V(X) = \\sigma_X^2 = \\int_{-\\infty}^{\\infty}(x - \\mu)^2 . f(x) \\ dx = E[(x- \\mu)^2]$$\n",
    "\n",
    "**Uniform Distribution**\n",
    "$$V(X) = \\frac{(B - A)^2}{12}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11. Standard Deviation of X\n",
    "$$\\sigma_X = \\sqrt{\\sigma_X^2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 12.Rules of Variance & Standard Deviation\n",
    "$$V[h(X)] = \\sigma_{h(X)}^2 = \\sum_D\\{h(X) - E[h(X)]\\}^2 .p(x)$$\n",
    "For any linear function $h(X) = aX + b $,\n",
    "$$Variance, \\ V(aX + b) = \\sigma_{aX + b}^2 = a^2. \\sigma_x^2 = a^2 . Var(X)$$\n",
    "\n",
    "$$Var(aX + bY) = a^2Var(X) + b^2Var(Y) + 2ab Cov(X,Y)$$\n",
    "$$Var(aX - bY) = a^2Var(X) + b^2Var(Y) - 2ab Cov(X,Y)$$\n",
    "If $X$ and $Y$ are independent,\n",
    "$$Var(X + Y)  = Var(X) + Var(Y) = Var(X - Y)$$\n",
    "\n",
    "$$Standard \\ Deviation, \\ \\sigma_{aX + b} = |a|. \\sigma_x$$\n",
    "$E[(X - a)^2]$ is a minumum when $$a = \\mu = E(X)$$\n",
    "\n",
    "Variance of any constant is zero and if a random variable has zero variance, then it is essentially constant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 13. Joint Distributions\n",
    "\n",
    "**Discrete RV**\n",
    "$$P(X_i, Y_j) = P[(X = X_i) \\cap (Y = Y_j)]$$\n",
    "where \n",
    "    $$p(x,y) \\geq 0$$ and\n",
    "    $$\\sum_x\\sum_yp(x,y) = 1$$\n",
    "For any 2 dimensional set A,\n",
    "$$P[(X,Y) \\in A] = \\sum_{(x,y)}\\sum_{\\in A}p(x,y)$$\n",
    "\n",
    "**Continuous RV**\n",
    "$$P(X_i, Y_j) = P[(X = X_i) \\cap (Y = Y_j)] $$\n",
    "where \n",
    "    $$p(x,y) \\geq 0$$ and\n",
    "    $$\\int_{-\\infty}^{\\infty}\\int_{-\\infty}^{\\infty}f(x,y) \\ dx \\ dy = 1$$\n",
    "For any 2 dimensional set A,\n",
    "$$P[(X,Y) \\in A] = \\int_A\\int f(x,y) \\ dx \\ dy$$\n",
    "\n",
    "If A is the two dimensional rectangle $\\{(x,y):a \\leq x \\leq b, c \\leq y \\leq d\\}$ , then\n",
    "$$P[(X,Y) \\in A] = P(a \\leq X \\leq b, c \\leq Y \\leq d)\\int_a^b\\int_c^d f(x,y) \\ dx \\ dy$$\n",
    "\n",
    "**CDF**\n",
    "$$F_{X,Y}(x,y) = P(X \\leq x, Y \\leq y)$$\n",
    "If $X$ and $Y$ are continuous random variables with joint density $f(x, y)$ over the range $[a, b] \\times [c, d]$\n",
    "$$F(x,y) = \\int_a^x\\int_c^y f(x,y) \\ dx \\ dy$$\n",
    "$$F(x,y) = \\sum_{x_i \\leq x}\\sum_{y_j \\leq y} p(x_i,y_j)$$\n",
    "\n",
    "**PDF**<BR>\n",
    "To get joint pdf from joint cdf,\n",
    "$$f_{X,Y}(x,y) = \\frac{d^2}{dxdy}F_{X,Y}(x,y)$$\n",
    "\n",
    "Example of a joint pdf:\n",
    "$$f(x,y) = \\begin{cases}\n",
    "24xy, & \\ 0 \\leq x \\leq 1, 0 \\leq y \\leq 1, x + y \\leq 1 \\\\\n",
    "0, & \\ otherwise\n",
    "\\end{cases}$$\n",
    "\n",
    "**Expected Value**\n",
    "$$E(XY) = \\sum_{i=1}^{N_X} \\sum_{j=1}^{N_Y} X_iY_j\\cdot P(X_i,Y_j) $$\n",
    "$$E[h(X,Y)] = \\sum_x\\sum_yh(x,y) \\cdot p(x,y)$$\n",
    "$$=\\int_{-\\infty}^{\\infty}\\int_{-\\infty}^{\\infty}h(x,y) \\cdot f(x,y) \\ dx \\ dy$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 14. Conditional Probability Density Function\n",
    "Let $X$ and $Y$ be two continuous rv’s with joint pdf $f(x, y)$ and marginal pdf of $X$ as $f_X(x)$. Then for any $X$ value $x$ for which $f_X(x) \\gt 0$, the conditional probability density function of $Y$ given that $X = x$ is\n",
    "$$f_{Y|X}(y|x) = \\frac{f(x,y)}{f_X(x)} \\ \\ -\\infty \\lt y \\lt \\infty$$\n",
    "If $X$ and $Y$ are discrete, replacing pdf’s by pmf’s in this definition gives the conditional probability mass function of $Y$ when $X = x$.\n",
    "\n",
    "This can also be written as\n",
    "$$ P(Y = Y_j | X = X_i)  = \\frac{P(X_i, Y_j)}{P(X = X_i)}$$\n",
    "\n",
    "$$\\implies P(X_i, Y_j) = P(Y = Y_j | X = X_i) \\cdot P(X = X_i)$$\n",
    "\n",
    "**Conditional Expectation**\n",
    "$$E(Y|X = X_i) = \\sum_{j = 1}^{N_Y} Y_j \\cdot P(Y = Y_j | X = X_i)$$\n",
    "$$=\\int_{-\\infty}^{\\infty}y \\cdot f_{X|Y}(y|x)dy$$\n",
    "\n",
    "**Properties of Conditional Expectations**\n",
    "- $E[c(X)|X] = c(X)$\n",
    "- $E[a(X)Y + b(X)|X] = a(X)E(Y|X) + b(X)$\n",
    "- If $X$ and $Y$ are independent, $E(Y|X) = E(Y)$\n",
    "\n",
    "**Conditional Variance**\n",
    "$$Var(Y|X = x) = E(Y^2|x) - [E(Y|x)]^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 15. Marginal Probability\n",
    "**Discrete RV**\n",
    "$$p_X(x) = \\sum_{y:p(x,y) \\gt 0}p(x,y) = \\sum_jp_{X,Y}(x_i, y_j) = p(x,y_1) + p(x, y_2) + ...$$\n",
    "Here x will be constant and will be summed for all possible values of y.\n",
    "$$p_Y(y) = \\sum_{x:p(x,y) \\gt 0}p(x,y) = \\sum_ip_{X,Y}(x_i, y_j) = p(x_1,y) + p(x_2,y) + ...$$\n",
    "Here y will be constant and will be summed for all possible values of x.\n",
    "\n",
    "**Continuous RV**\n",
    "$$f_X(x) = \\int_{-\\infty}^{\\infty}f(x,y) dy \\ \\ for -\\infty \\lt x \\lt \\infty$$\n",
    "$$f_Y(y) = \\int_{-\\infty}^{\\infty}f(x,y) dx \\ \\ for -\\infty \\lt y \\lt \\infty$$\n",
    "$$f_Y(y) = \\int_{-\\infty}^{\\infty}f_{Y|X}(y|x)f_X(x) dx \\ \\ for -\\infty \\lt y \\lt \\infty$$\n",
    "\n",
    "**CDF**<BR>\n",
    "If $X$ and $Y$ jointly take values on $[a,b] \\times [c,d]$\n",
    "$$F_X(x) = F(x,d), F_Y(y) = F(b,y)$$\n",
    "If $d$ is $\\infty$ then this becomes a limit \n",
    "$$F_X(x) = \\lim_{y \\to \\infty}F(x,y), F_Y(y) = \\lim_{x \\to \\infty}F(x,y)$$\n",
    "\n",
    "**Expectation**\n",
    "$$E(X) = \\sum_x x f_X(x) = \\sum_x x \\sum_yp_{X,Y}(x, y)$$\n",
    "$$E(Y) = \\sum_y y f_Y(y) = \\sum_y y \\sum_xp_{X,Y}(x, y)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 16. Independent RV\n",
    "**Discrete**\n",
    "$$p(x,y) = p_X(x) \\cdot p_Y(y)$$\n",
    "For discrete variables independence means the probability in a cell must be the product of the marginal probabilities of its row (entire) and column(entire)\n",
    "\n",
    "**Continuous**\n",
    "If $X$ and $Y$ are independent, then\n",
    "$$f_{X|Y}(x,y) = f_X(x)$$\n",
    "$$\\implies f_{X|Y}(x,y) = \\frac{f(x,y)}{f_Y(y)} = f_X(x)$$\n",
    "$$\\implies f(x,y) = f_X(x) \\cdot f_Y(y)$$\n",
    "\n",
    "To be independent, $f(x, y)$ must have the form $g(x) \\cdot h(y)$ and the region of positive density must be a rectangle whose sides are parallel to the coordinate axes.\n",
    "$$P(a \\leq X \\leq b, c \\leq Y \\leq d) = P(a \\leq X \\leq b) \\cdot P(c \\leq Y \\leq d)$$\n",
    "Equivalently,\n",
    "$$F(X,Y) = F_X(x)F_Y(y)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 17. Law of iterated expectations\n",
    "\n",
    "$$ E(Y) = E[E(Y|X)] = E_X[E(Y|X=x)]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 18. Covariance\n",
    "\n",
    "Covariance measures the amount of **linear dependence** between two random variables. \n",
    "$$Cov(X, Y) = \\sigma_{XY} = E[(X - \\mu_X)(Y - \\mu_Y)] = E(XY) - E(X)E(Y)$$\n",
    "$$=\\sum_x\\sum_y(x - \\mu_X)(y - \\mu_Y)p(x,y) = \\biggl(\\sum_x\\sum_y xyp(x,y)\\biggl) - \\mu_X\\mu_Y$$\n",
    "$$=\\int_{-\\infty}^{\\infty}\\int_{-\\infty}^{\\infty}(x - \\mu_X)(y - \\mu_Y)f(x,y) \\ dx \\ dy =\\biggl(\\int_a^b\\int_c^dxyf(x,y) \\ dx \\ dy \\biggl) - \\mu_X\\mu_Y $$\n",
    "\n",
    "$$Cov(X, X) = E[(X - \\mu_X)^2] = V(X)$$\n",
    "If $X$ and $Y$ are independent, \n",
    "$$Cov(X,Y) = 0$$\n",
    "\n",
    "Also,\n",
    "$$Cov(aX + b, cY + d) = acCov(X,Y)$$\n",
    "$$Cov(X, Y+Z) = Cov(X,Y) + Cov(X,Z)$$\n",
    "\n",
    "**Cauchy Schwartz Inequality**\n",
    "$$|Cov(X,Y)| \\leq sd(X)sd(Y)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 19. Correlation\n",
    "$$\\rho_{X,Y} = \\frac{Cov(X,Y)}{\\sigma_X \\cdot \\sigma_Y}$$\n",
    "\n",
    "**Rules of Correlation**<BR>\n",
    "* If $a$ and $c$ are either both positive or both negative,\n",
    "$$Corr(aX + b, cY + d) = Corr(X,Y)$$\n",
    "* If $ac \\lt 0$ ,\n",
    "$$Corr(aX + b, cY + d) = -Corr(X,Y)$$\n",
    "* For any two rv’s X and Y, \n",
    "$$-1 \\leq  Corr(X, Y) \\leq 1$$\n",
    "\n",
    "* If $X$ and $Y$ are independent, then $\\rho = 0$, but $\\rho = 0$ does not imply independence.<BR>\n",
    "* $\\rho = 1 \\ or \\ -1$ iff $Y = aX + b$ for some numbers $a$ and $b$ with $a \\neq 0$.\n",
    "* For descriptive purposes, the relationship will be described as strong if $| \\rho | \\geq .8$, moderate if $.5 \\lt |\\rho | \\lt .8$, and weak if $| \\rho| \\leq .5$.\n",
    "* $\\rho$ is the covariance of the standardizations of $X$ and $Y$\n",
    "* $\\rho$ is dimensionless (it's a ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 20. Multinomial Distribution\n",
    "$$p(x_1, x_2,...,x_n) = \\begin{cases}\n",
    "\\frac{n!}{(x_1!)(x_2!)...(x_n!)} p_1^{x_1}...p_r^{x_r} & \\ x_i = 0,1,2..., with \\ x_1 +...+x_r = n \\\\\n",
    "0, & \\ otherwise\n",
    "\\end{cases}$$\n",
    "The case $r = 2$ gives the binomial distribution, with $X1$ = number of successes and $X2 = n - X1$ = number of failures.\n",
    "\n",
    "**PMF**\n",
    "$$p(x_1, x_2,...,x_n) = P(X_1 = x_1, X_2 = x_2,...,X_n = x_n)$$\n",
    "\n",
    "**PDF**\n",
    "$$P(a_1 \\leq X_1 \\leq b_1,...,a_n \\leq X_n \\leq b_n) = \\int_{a_1}^{b_1}...\\int_{a_n}^{b_n}f(x_1,...,x_n)dx_n...dx_1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 21. Distribution of Sample Mean\n",
    "Let $X_1, X_2, . . . , X_n$ be a random sample from a distribution with mean value $\\mu$ and standard deviation $\\sigma$. Then\n",
    "\n",
    "$$E(\\overline X) = \\mu_{\\overline X} = \\mu$$\n",
    "$$V(\\overline X) = \\sigma_{\\overline X}^2 = \\sigma^2/n$$\n",
    "$$\\sigma_{\\overline X} = \\sigma/\\sqrt n$$\n",
    "\n",
    "In addition, with $T_o = X_1 + . . . + X_n$ (the sample total), \n",
    "$$E(T_o) = n\\mu, V(T_o) = n\\sigma^2 , and \\  \\sigma_{T_o} = \\sqrt n \\sigma$$\n",
    "\n",
    "The values of $\\overline{X}_n - E(X)$ are generally closer to zero as the sample size increases. \n",
    "\n",
    "To quantify how \"fast\" $\\overline{X}_n - E(X)$ converges to zero, we usually find a sequence of numbers $\\{a_n\\}_{n=1}^\\infty$ so that \n",
    "\n",
    "$$a_n(\\overline{X}_n -E(X))$$\n",
    "\n",
    "neither *converges* to zero nor *diverges* to $\\infty$ \n",
    "\n",
    "It turns out that under very general conditions that sequence is $a_n = \\sqrt{n}$ ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 22. I.I.D. Observations \n",
    "\n",
    "* *independent observations*: $ P \\big( [X_i= a] \\cap [X_j = b]\\big) = P(X_i = a)P(X_j = b)$ for all $i\\neq j$\n",
    "\n",
    "* *identically distributed*: The distribution of the values of each observation are the same which implies that for all $i \\neq j$\n",
    "\n",
    "$$ E(X_i) = E(X_j) = E(X)  \\;\\; \\text{ and } \\;\\; V(X_i) = V(X_j) = V(X)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 23. Central Limit Theorem\n",
    "Let $X_1, X_2,…, X_n$ be a random sample from a distribution with mean$\\mu$ and variance $\\sigma^2$. Then if $n$ is sufficiently large, $\\overline X$ has approximately a normal distribution with $\\mu_{\\overline X} = \\mu$ and $\\sigma_{\\overline X}^2 = \\sigma^2/n$, and $T_o$ also has approximately a normal distribution with $\\mu_{T_o} = n\\mu, \\sigma^2_{T_o} = n\\sigma^2$. The larger the value of $n$, the better the approximation.\n",
    "\n",
    "If\n",
    "$$T_o = X_1 + X_2 + ... + X_n \\ \\ (n=1,2,...),$$\n",
    "$$\\lim_{n \\to \\infty} p \\biggl(a \\leq \\frac{T_o - n \\mu}{\\sigma\\sqrt{n}} \\leq b \\biggl) = \\frac{1}{\\sqrt{2 \\pi}} \\int_a^b e^{-u^2/2}du$$\n",
    "where $\\frac{T_o - n \\mu}{\\sigma\\sqrt{n}}$ is the standardized random variable\n",
    "\n",
    "\n",
    "** Lindeberg–Lévy CLT ** <BR>\n",
    "if\n",
    "* $E(X) = \\mu $ and $-\\infty < \\mu  < \\infty$, i.e. $E(X)$ has to be finite\n",
    "\n",
    "* $V(X) = \\sigma^2 < \\infty $, i.e. $V(X)$ has to be finite\n",
    "\n",
    "* $\\{X_i\\}_{i=1}^n$ are i.i.d observations \n",
    "\n",
    "then, \n",
    "\n",
    "$$ \\sqrt{n}(\\overline{X}_n - \\mu) \\stackrel{d}{\\longrightarrow} N(0,\\sigma^2) $$\n",
    "or of more practical use, for n \"large\" \n",
    "$$ \\overline{X}_n  \\sim N \\left(\\mu,\\frac{\\sigma^2}{\\sqrt{n}} \\right) $$\n",
    "where $\\sim$ means \" is approximately distributed as\" \n",
    "\n",
    "**Law of Large Numbers (LLN)**<BR>\n",
    "**If**: $E(X_i) < \\infty$, **and**  $f(X_1,X_2, \\ldots,X_n) = n^{-1}\\sum_{i=1}^n X_i \\; $ **and** $\\{X_{i}\\}_{i=1}^n$ is an i.i.d random sample **then**    \n",
    "\n",
    "$$ \\left| n^{-1}\\sum_{i=1}^n X_i - E(X) \\right| \\stackrel{p}{\\rightarrow} 0 $$\n",
    "\n",
    "** Weak Law of Large Numbers ** <BR>\n",
    "For any $\\epsilon \\gt 0$\n",
    "$$\\lim_{n \\to \\infty}P(|\\overline X_n - \\mu| \\lt \\epsilon) = 1$$\n",
    "$$\\overline X_n \\xrightarrow{P} \\mu \\ as \\ n \\to \\infty$$\n",
    "    \n",
    "The CDFs of $Z_n$ converge to $\\phi(z)$:\n",
    "$$\\lim_{n \\to \\infty} F_{Z_n}(z) = \\phi(z)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 24. Linear Combination RV\n",
    "$$Y = a_1X_1 + ... + a_nX_n = \\sum_{i = 1}^na_iX_i$$\n",
    "where $X_1, . . . , X_n$ are a collection of $n$ random variables and $n$ numerical constants $a_1, . . . , a_n$\n",
    "\n",
    "Taking $a_1 = a_2 =... = a_n = 1$ gives\n",
    "$$Y = X_1 + ... + X_n = T_o$$\n",
    "and $a_1 = a_2 =... = a_n = 1/n$ yields\n",
    "$$Y = \\frac{1}{n}X_1 + ... + \\frac{1}{n}X_n = \\frac{1}{n}T_o = \\overline X$$\n",
    "\n",
    "Here $X_i$ ’s don't have to be independent or identically distributed. All the $X_i$ ’s could have different distributions and therefore different mean values and variances.<BR>\n",
    "    \n",
    "**Expectation**<BR>\n",
    "Whether or not the $X_i$ ’s are independent, \n",
    "    $$E(a_1X_1 + a_2X_2 + . . . + a_nX_n) = a_1E(X_1) + a_2E(X_2) + ... + a_nE(X_n) = a_1\\mu_1 + ... + a_n\\mu_n$$\n",
    "    $$E\\biggl(\\sum_{i=1}^n a_i X_i \\biggl) = \\sum_{i=1}^n a_i E(X_i)$$\n",
    "\n",
    "**Variance**<BR>\n",
    "The random variables ${X_1, ... , X_n}$ are **pairwise uncorrelated random variables** if each variable in the set is uncorrelated with every other variable in the set. That is, $Cov(X_i , X_j) = 0$, for all $i \\neq j$.\n",
    "    \n",
    "If $X_1, . . . , X_n$ are independent,\n",
    "$$V(a_1X_1 + a_2X_2 + ... + a_nX_n) = a_1^2V(X_1) + a_2^2V(X_2) + ... + a_n^2V(X_n) = a_1^2\\sigma_1^2 + a_2^2\\sigma_2^2 + ... + a_n^2\\sigma_n^2$$\n",
    "and \n",
    "$$\\sigma_{a_1X_1 + ... + a_nX_n}= \\sqrt{a_1^2\\sigma_1^2 + a_2^2\\sigma_2^2 + ... + a_n^2\\sigma_n^2}$$\n",
    "\n",
    "For any $X_1, . . . , X_n$,\n",
    "$$V\\biggl(\\sum_{i=1}^n a_i X_i \\biggl) = \\sum_{i=1}^n a_i^2 V(X_i)$$\n",
    "$$V(a_1X_1 + a_2X_2 + ... + a_nX_n) = \\sum_{i = i}^n\\sum_{j = 1}^na_ia_jCov(X_i, X_j)$$\n",
    "$$V(a_1X_1 + a_2X_2) = a_1^2V(X_1) + a_2^2V(X_2) + 2a_1a_2Cov(X_1, X_2)$$\n",
    "\n",
    "For random sample ($X_i$ 's iid) with $a_1 = a_2 =... = a_n = 1/n$, \n",
    "$$E(\\overline X) = \\mu, V(\\overline X) = \\sigma^2/n$$\n",
    "\n",
    "**Special Case**<BR>\n",
    "If $n=2$ and $a_1 = 1$ and $a_2 = -1$, then\n",
    "$$E(X1 - X2) = E(X1) - E(X2)$$ for any two rv’s X1 and X2. $$V(X1 - X2) = V(X1) + V(X2)$$ if X1 and X2 are independent rv’s."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Higher Order Moments - Skewness and Kurtosis\n",
    "\n",
    "Third moment of standard normal RV $Z$ is used to determine skewness\n",
    "$$E(Z^3) = \\frac{E[(X - \\mu)^3]}{\\sigma^3}$$\n",
    "\n",
    "Fourth moment of standard normal RV $Z$ is used to determine kurtosis\n",
    "$$E(Z^4) = \\frac{E[(X - \\mu)^4]}{\\sigma^4}$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
